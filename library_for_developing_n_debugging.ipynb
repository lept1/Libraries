{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer,KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB,ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "\n",
    "import itertools\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now=datetime.now()\n",
    "\n",
    "models = OrderedDict([\n",
    "          ('Knn', KNeighborsClassifier()),\n",
    "          ('Logistic Regression', LogisticRegression(max_iter=10000)),\n",
    "          ('Linear SVM', SVC(kernel='linear', probability=True)),\n",
    "          ('Poly SVM', SVC(kernel='poly',  probability=True)),\n",
    "          ('RBF SVM', SVC(kernel='rbf',  probability=True)),\n",
    "          ('Classification Tree', DecisionTreeClassifier()),\n",
    "          ('Random Forest', RandomForestClassifier()),\n",
    "          ('MLP', MLPClassifier(activation='tanh',solver='adam', max_iter=10000,\n",
    "                                                  learning_rate_init=0.001, random_state=42)),\n",
    "          ('AdaBoost',AdaBoostClassifier(random_state=42,base_estimator = RandomForestClassifier())),\n",
    "          ('GBoost',GradientBoostingClassifier()),\n",
    "          ('Knn Regression', KNeighborsRegressor(weights='distance')),\n",
    "          ('Linear Regression', LinearRegression(fit_intercept=True,normalize=True)),\n",
    "          ('Ridge', Ridge(fit_intercept=True,normalize=True)),\n",
    "          ('Lasso', Lasso()),  \n",
    "          ('Tree Regression', DecisionTreeRegressor()),\n",
    "          ('Random Forest Regression', RandomForestRegressor()),\n",
    "          ('GBoost Regression', GradientBoostingRegressor()),\n",
    "          ('Gaussian NB', GaussianNB()),\n",
    "          ('Multinomial NB', MultinomialNB()),\n",
    "          ('Complement NB',ComplementNB())\n",
    "          ])\n",
    "\n",
    "\n",
    "def training(X,y,model='Logistic Regression',cv=5,score='accuracy_score',p_name=now.strftime('%m-%Y'),save=False):\n",
    "    # X      : array-like or sparse matrix, shape (n_samples, n_features)\n",
    "    # y      : array-like of shape (n_samples,)\n",
    "    # model  : string, classification model ::\n",
    "    #                - Logistic Regression (default)\n",
    "    #                - Knn (K - nearest neighbours)\n",
    "    #                - Linear SVM\n",
    "    #                - Poly SVM\n",
    "    #                - RBF SVM\n",
    "    #                - Classification Tree\n",
    "    #                - Random Forest\n",
    "    #                - MLP (Multi Layer Perceptron)\n",
    "    #                - AdaBoost\n",
    "    #                - GBoost (Gradient Boosting)\n",
    "    # cv     : int, cross-validation generator, default=5\n",
    "    # score  : string, strategy to evaluate the performance of the cross-validated model on the test set ::\n",
    "    #                - f1_score\n",
    "    #                - accuracy_score\n",
    "    #                - precision_score\n",
    "    #                - neg_mean_squared_error (for regression problem\n",
    "    #p_name  : string, name of the project/kaggle\n",
    "\n",
    "    \n",
    "    \n",
    "    scorers = {'f1_score': make_scorer(f1_score, average = 'weighted'),\n",
    "              'accuracy_score': make_scorer(accuracy_score),\n",
    "              'precision_score': make_scorer(precision_score, average = 'weighted')}\n",
    "    \n",
    "    try:\n",
    "        filename = model+'.sav'\n",
    "        gs=joblib.load(filename)\n",
    "        message=filename + ' already exists'\n",
    "        print(message)\n",
    "        return gs\n",
    "        \n",
    "    except:\n",
    "\n",
    "        if model=='Knn':\n",
    "            n_neighbors=np.arange(1,30,1)\n",
    "            knn=models[model]\n",
    "            gs = GridSearchCV(knn,param_grid={\"n_neighbors\": n_neighbors},scoring=scorers,refit=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='Gaussian NB':\n",
    "            var_smoothing=np.logspace(-10,-3,30)\n",
    "            gnb=models[model]\n",
    "            gs = GridSearchCV(gnb,param_grid={\"var_smoothing\": var_smoothing},scoring=scorers,refit=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            if scp.sparse.issparse(X):\n",
    "                Z=X.toarray()\n",
    "                gs.fit(Z, y)\n",
    "            else:\n",
    "                gs.fit(X, y)\n",
    "\n",
    "        if model=='Multinomial NB':\n",
    "            alpha=np.logspace(-3,0,20)\n",
    "            mnb=models[model]\n",
    "            gs = GridSearchCV(mnb,param_grid={\"alpha\": alpha},scoring=scorers,refit=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='Complement NB':\n",
    "            alpha=np.logspace(-3,0,20)\n",
    "            mnb=models[model]\n",
    "            gs = GridSearchCV(mnb,param_grid={\"alpha\": alpha},scoring=scorers,refit=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "            \n",
    "        if model=='Logistic Regression':\n",
    "            C  = np.logspace(-3,2,10)\n",
    "            lr = models[model]\n",
    "            gs = GridSearchCV(lr,param_grid={\"C\": C},scoring=scorers,refit=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='Linear SVM':\n",
    "            C=np.logspace(-3,2,10)\n",
    "            lsvm=models[model]\n",
    "            gs = GridSearchCV(lsvm,param_grid={\"C\": C},scoring=scorers,refit=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='RBF SVM':\n",
    "            gamma=np.logspace(-4,1,10)\n",
    "            C=np.logspace(-3,3,10)\n",
    "            rsvm=models[model]\n",
    "            gs = GridSearchCV(rsvm,param_grid={\"C\": C,\"gamma\":gamma},scoring=scorers,refit=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='Classification Tree':\n",
    "            max_depth=np.arange(1,50,1)\n",
    "            ct=models[model]\n",
    "            gs = GridSearchCV(ct,param_grid={\"max_depth\": max_depth},scoring=scorers,refit=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='Random Forest':\n",
    "            max_depth=np.arange(1,50,5)\n",
    "            n_estimators=np.arange(1,50,5)\n",
    "            rf=models[model]\n",
    "            gs = GridSearchCV(rf,param_grid={\"max_depth\": max_depth,\"n_estimators\": n_estimators},scoring=scorers,refit=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='MLP':\n",
    "            hidden_layer_sizes=[(12,4,2),(6,5,4,3,2),(7,6,5,4,3,2),(8,7,6,5,4,3,2)]\n",
    "            mlp=models[model]\n",
    "            gs = GridSearchCV(mlp,param_grid={\"hidden_layer_sizes\": hidden_layer_sizes},scoring=scorers,refit='accuracy_score',cv=cv,n_jobs=-3,verbose=5)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='AdaBoost':\n",
    "            param_grid = {\"algorithm\" : ['SAMME', 'SAMME.R'],\n",
    "                  \"n_estimators\" : np.arange(1,50,1)\n",
    "                 }\n",
    "            ab=models[model]\n",
    "            gs = GridSearchCV(ab,param_grid=param_grid,scoring=scorers,refit='accuracy_score',cv=cv,n_jobs=-3,verbose=5)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='GBoost':\n",
    "            param_grid = {\"n_estimators\": np.arange(1,100,2)}\n",
    "            gb=models[model]\n",
    "            gs = GridSearchCV(gb,param_grid=param_grid,scoring=scorers,refit='accuracy_score',cv=cv,n_jobs=-3,verbose=5)\n",
    "            gs.fit(X, y)\n",
    "            \n",
    "        if model=='Knn Regression':\n",
    "            n_neighbors=[1,2,3,4,5,10,20,30]\n",
    "            gb=models[model]\n",
    "            gs = GridSearchCV(gb,param_grid={\"n_neighbors\": n_neighbors},scoring=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='Ridge':\n",
    "            alpha  = np.logspace(0,1,5)\n",
    "            lr = models[model]\n",
    "            gs = GridSearchCV(lr,param_grid={\"alpha\": alpha},scoring=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='Lasso':\n",
    "            alpha  = np.logspace(0,5,5)\n",
    "            lr = models[model]\n",
    "            gs = GridSearchCV(lr,param_grid={\"alpha\": alpha},scoring=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='Tree Regression':\n",
    "            max_depth=[30,40,50,100]\n",
    "            rt=models[model]\n",
    "            gs = GridSearchCV(rt,param_grid={\"max_depth\": max_depth},scoring=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='Random Forest Regression':\n",
    "            max_depth=np.arange(1,100,10)\n",
    "            n_estimators=np.arange(3,21,3)\n",
    "            rf=models[model]\n",
    "            gs = GridSearchCV(rf,param_grid={\"max_depth\": max_depth,\"n_estimators\": n_estimators},scoring=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "        if model=='GBoost Regression':\n",
    "            max_depth=np.arange(1,100,10)\n",
    "            n_estimators=np.arange(3,21,3)\n",
    "            br=models[model]\n",
    "            gs = GridSearchCV(br,param_grid={\"max_depth\": max_depth,\"n_estimators\": n_estimators},scoring=score,cv=cv,n_jobs=-3,verbose=2)\n",
    "            gs.fit(X, y)\n",
    "\n",
    "\n",
    "        if save==True:\n",
    "            save_model(gs,model)\n",
    "    print('best score = ', gs.best_score_)\n",
    "    print('best parameters = ', gs.best_params_)\n",
    "    return gs \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def features_identification(X, min_fraction_unique=0.05):\n",
    "    # X : pd.DataFrame, dataframe\n",
    "\n",
    "    unique_fraction      = X.apply(lambda col: len(pd.unique(col))/len(col))\n",
    "    print (unique_fraction.shape)\n",
    "    categorical_features = unique_fraction.index[unique_fraction<min_fraction_unique].tolist()\n",
    "    numerical_features   = unique_fraction.index[unique_fraction>=min_fraction_unique].tolist()\n",
    "\n",
    "    return categorical_features,numerical_features    \n",
    "    \n",
    "    \n",
    "def preprocessing(X):\n",
    "    # X : pandas dataframe\n",
    "    \n",
    "    categorical_features, numeric_features  = features_identification(X)\n",
    "    \n",
    "    print (categorical_features, ' CAT')\n",
    "    print (numeric_features, 'NUM')\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[('imputer_numeric', KNNImputer(n_neighbors=4)),\n",
    "                                            ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[('imputer_categorical', SimpleImputer(strategy='most_frequent')),\n",
    "                                                ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    return preprocessor\n",
    "\n",
    "\n",
    "def graph(X,label):\n",
    "    \n",
    "    cmap1 = sns.color_palette(\"crest\", as_cmap=True)\n",
    "    \n",
    "    categorical_features, numeric_features  = features_identification(X)\n",
    "    i=0\n",
    "    for cat in categorical_features:\n",
    "        shape_color=len(X[cat].unique())\n",
    "        plt.figure(i)\n",
    "        sns.countplot(y=label, hue=cat, data=X, palette=sns.color_palette(\"YlGn\", shape_color))\n",
    "        i+=1\n",
    "    for num in numeric_features:\n",
    "        shape_color=len(X[label].unique())\n",
    "        X.pivot(columns=[label])[num].plot(kind = 'hist', stacked=True,bins=80,figsize=(15,7),color=sns.color_palette(\"YlGn\", shape_color))\n",
    "        plt.xlabel(num)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,target_names,title='Confusion matrix', cmap=None,normalize=True):\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "def plot_correlation_matrix(X, size=(8,3) ):\n",
    "    corr = X.corr()\n",
    "    f, ax = plt.subplots(figsize=size)\n",
    "    cmap = sns.diverging_palette(245, 10, as_cmap=True)\n",
    "    sns.heatmap(corr, cmap=cmap,vimax=1,vimin=-1,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def save_model(model, name):\n",
    "    filename = name+'.sav'\n",
    "    joblib.dump(model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
